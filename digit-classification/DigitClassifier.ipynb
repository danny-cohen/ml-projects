{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer (Multiclass Classification)\n",
    "\n",
    "https://www.kaggle.com/c/digit-recognizer/data\n",
    "\n",
    "__Data__\n",
    "\n",
    "train.csv: training set\n",
    "\n",
    "test.csv: test set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in training and test data (consisting of images and labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: uint8(785)\n",
      "memory usage: 31.4 MB\n",
      "\n",
      "\n",
      "\n",
      "Test set:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: uint8(784)\n",
      "memory usage: 20.9 MB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg \n",
    "import numpy as np\n",
    "import os \n",
    "import tarfile\n",
    "import urllib \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    " \n",
    "# Use pandas to retrieve data file\n",
    "#url = '' # use to fetch data file each time\n",
    "\n",
    "# Read in CSV file with probabilities\n",
    "#help(pd.read_csv)\n",
    "traindata = pd.read_csv(\"train.csv\",dtype=np.uint8)\n",
    "testdata = pd.read_csv(\"test.csv\",dtype=np.uint8)\n",
    "\n",
    "# Check train/test data frame headers, columns\n",
    "print(\"Train set:\\n\")\n",
    "traindata.info()\n",
    "print('\\n\\n')\n",
    "\n",
    "print(\"Test set:\\n\")\n",
    "testdata.info()\n",
    "print('\\n')\n",
    "\n",
    "# Define train data: y=target (labels) and X=features (pixel values)\n",
    "y_train=traindata.label\n",
    "X_train=traindata.loc[:,'pixel0':'pixel783']\n",
    "\n",
    "# Define test data: just pixel values \n",
    "X_test=testdata.loc[:,'pixel0':'pixel783']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some functions for dealing with the digits as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reshape list of flattened (1D) images into list of 2D images\n",
    "# def make_digit_images(x,image_size=(28,28)):\n",
    "\n",
    "#     n_sample=x.shape[0]\n",
    "    \n",
    "#     x_2D = np.reshape(x, (n_sample,)+image_size)\n",
    "    \n",
    "#     return x_2D\n",
    "\n",
    "\n",
    "# function to display digits as 2D images given X, with flattened images\n",
    "def plot_digits(x,image_size=(28,28)):\n",
    "    \n",
    "    n_sample=x.shape[0]\n",
    "    \n",
    "    x_2D = np.reshape(x, (n_sample,)+image_size)\n",
    "\n",
    "    ncol=10\n",
    "    nrow=n_sample//ncol\n",
    "    \n",
    "    plt.figure(1, (ncol*1.2,nrow*1.2))\n",
    "    for i in range(n_sample):\n",
    "        ax_i=plt.subplot(nrow,ncol,i+1)\n",
    "        ax_i.imshow(x_2D[i,:,:],cmap='Greys')\n",
    "        ax_i.set_xticklabels([])\n",
    "        ax_i.set_yticklabels([])\n",
    "     \n",
    "    plt.subplots_adjust(wspace=0,hspace=0)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "# function to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_train.values[:100,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: The pixel values are already on same scale so no scaling should be required for $\\mathbf{X}$ (values between 0-255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Stochastic Gradient Descent Classifier ```sklearn.linear_model.SGDClassifier``` (capable of multi-class)\n",
    "\n",
    "Loss function should be ```log``` or ```modified_huber```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42,shuffle=True,loss='modified_huber',max_iter=1000,tol=1.0e-2)#learning_rate='constant')\n",
    "\n",
    "sgd_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.classes_,sgd_clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation to evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cv_scores=cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3, n_jobs=3)\n",
    "\n",
    "C_matrix = confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CV accuracy scores:\")\n",
    "[print(\"%.1f PCT\"%(cv*100)) for cv in cv_scores]\n",
    "\n",
    "print(\"Confusion matrix: \")\n",
    "print(C_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix):\n",
    "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(C_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot matrix of error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display error matrix (): normalize by row and fill the correct predictions (diagnols) with zeros\n",
    "row_sums =C_matrix.sum(axis=1, keepdims=True)\n",
    "norm_C_matrix =C_matrix / row_sums\n",
    "np.fill_diagonal(norm_C_matrix, 0)\n",
    "plot_confusion_matrix(norm_C_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_a, cl_b = 5, 8\n",
    "X_aa = X_train.values[(y_train.values == cl_a) & (y_train_pred == cl_a), :]\n",
    "X_ab = X_train.values[(y_train.values == cl_a) & (y_train_pred == cl_b), :]\n",
    "X_ba = X_train.values[(y_train.values == cl_b) & (y_train_pred == cl_a), :]\n",
    "X_bb = X_train.values[(y_train.values == cl_b) & (y_train_pred == cl_b), :]\n",
    "\n",
    "#plt.figure(figsize=(8,8))\n",
    "print(\"Correctly predicted: \")\n",
    "plot_digits(X_aa[:40,:])\n",
    "\n",
    "plot_digits(X_bb[:40,:])\n",
    "\n",
    "print(\"Wrongly predicted: \")\n",
    "\n",
    "plot_digits(X_ab[:40,:])\n",
    "\n",
    "plot_digits(X_ba[:40,:])\n",
    "\n",
    "#plot_digits(X_bb[:30,:])\n",
    "#save_fig(\"error_analysis_digits_plot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Achieving a more accurate classifier: KNN model, grid search CV to find optimal parameters, and preprocess images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try ```KNeighborsClassifier``` with default paramters, no scaling or pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([15822.,  1156.,  1190.,  1018.,  1048.,  1108.,  1182.,  1345.,\n",
       "         1595., 16536.]),\n",
       " array([  0. ,  25.5,  51. ,  76.5, 102. , 127.5, 153. , 178.5, 204. ,\n",
       "        229.5, 255. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_2D = np.reshape(X_train.values, (X_train.values.shape[0],)+(28,28))\n",
    "print(X_train_2D.shape)\n",
    "plt.hist(X_train_2D[:,14,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(weights='distance',n_neighbors=4)\n",
    "\n",
    "knn_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cv_scores_knn=cross_val_score(knn_clf, X_train, y_train, cv=3, scoring=\"accuracy\", verbose=3)\n",
    "\n",
    "#y_train_pred_knn = cross_val_predict(knn_clf, X_train, y_train, cv=3)\n",
    "\n",
    "#C_matrix_knn = confusion_matrix(y_train, y_train_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classifier with no pre-processing is 96.7% accurate - try scaling pixel values to break 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_scaled=StandardScaler().fit_transform(X_train.astype(np.float64))\n",
    "print(X_train_scaled.shape,X_train.shape)\n",
    "c=['pixel%i'%n for n in np.arange(0,784)]\n",
    "print(c[-10:])\n",
    "\n",
    "X_train_scaled=pd.DataFrame(X_train_scaled,columns=c)\n",
    "\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(weights='distance',n_neighbors=4)\n",
    "\n",
    "knn_clf.fit(X_train_scaled,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cv_scores_knn=cross_val_score(knn_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlpy] *",
   "language": "python",
   "name": "conda-env-mlpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
